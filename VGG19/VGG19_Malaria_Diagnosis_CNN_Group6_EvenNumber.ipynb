{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_hxzrVpanrY"
      },
      "source": [
        "# Deep Learning for Malaria Diagnosis\n",
        "This notebook is inspired by works of (Sivaramakrishnan Rajaraman  et al., 2018) and (Jason Brownlee, 2019). Acknowledge to NIH and Bangalor Hospital who make available this malaria dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DyHvXlda9rH"
      },
      "source": [
        "Malaria is an infectuous disease caused by parasites that are transmitted to people through the bites of infected female Anopheles mosquitoes.\n",
        "\n",
        "The Malaria burden with some key figures:\n",
        "<font color='red'>\n",
        "* More than 219 million cases\n",
        "* Over 430 000 deaths in 2017 (Mostly: children & pregnants)\n",
        "* 80% in 15 countries of Africa & India\n",
        "  </font>\n",
        "\n",
        "![MalariaBurd](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/MalariaBurden.png?raw=1)\n",
        "\n",
        "The malaria diagnosis is performed using blood test:\n",
        "* Collect patient blood smear\n",
        "* Microscopic visualisation of the parasit\n",
        "\n",
        "![MalariaDiag](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/MalariaDiag.png?raw=1)\n",
        "  \n",
        "Main issues related to traditional diagnosis:\n",
        "<font color='#ed7d31'>\n",
        "* resource-constrained regions\n",
        "* time needed and delays\n",
        "* diagnosis accuracy and cost\n",
        "</font>\n",
        "\n",
        "The objective of this notebook is to apply modern deep learning techniques to perform medical image analysis for malaria diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5qBTeqkrJ88"
      },
      "source": [
        "*This notebook is inspired by works of (Sivaramakrishnan Rajaraman  et al., 2018), (Adrian Rosebrock, 2018) and (Jason Brownlee, 2019)*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 1: INTRODUCTION"
      ],
      "metadata": {
        "id": "uRpyqoP7Je0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MALARIA DIAGNOSIS: PROBLEM STATEMENT AND IMPORTANCE\n",
        "\n",
        "Malaria remains one of the world's most deadly infectious diseases, causing over\n",
        "200 million cases and hundreds of thousands of deaths annually, primarily in\n",
        "sub-Saharan Africa. Traditional diagnosis relies on microscopic examination of\n",
        "blood smears by trained technicians, a process that is:\n",
        "\n",
        "1. Time-consuming and labor-intensive\n",
        "2. Dependent on expert availability (limited in rural areas)\n",
        "3. Prone to human error and fatigue\n",
        "4. Inconsistent across different observers\n",
        "\n",
        "IMPORTANCE OF AUTOMATED DIAGNOSIS:\n",
        "\n",
        "Automated malaria detection using deep learning offers several advantages:\n",
        "- Rapid screening of large numbers of samples\n",
        "- Consistent, objective diagnoses\n",
        "- Deployment in resource-limited settings\n",
        "- Reduced burden on healthcare workers\n",
        "- Early detection and treatment, reducing mortality\n",
        "\n",
        "This project applies transfer learning with VGG19, a state-of-the-art CNN\n",
        "pre-trained on ImageNet, to classify cell images as infected or uninfected\n",
        "with malaria parasites.\n",
        "\n",
        "DATASET:\n",
        "- Source: NIH National Library of Medicine\n",
        "- Total Images: ~27,500 cell images\n",
        "- Classes: Parasitized (Infected) and Uninfected\n",
        "- Split: 80% training (22,046 images), 20% testing (5,512 images)"
      ],
      "metadata": {
        "id": "7gXS6WiDJfZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 2: LITERATURE REVIEW"
      ],
      "metadata": {
        "id": "tw5cO251Jryb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONVOLUTIONAL NEURAL NETWORKS IN MEDICAL IMAGE ANALYSIS\n",
        "\n",
        "CNNs have revolutionized medical image analysis due to their ability to\n",
        "automatically learn hierarchical feature representations. Key developments:\n",
        "\n",
        "1. DEEP LEARNING IN MEDICAL IMAGING (2012-Present):\n",
        "   - AlexNet (2012) demonstrated CNNs could outperform traditional methods\n",
        "   - CNNs now achieve expert-level performance in many diagnostic tasks\n",
        "   - Applications: cancer detection, diabetic retinopathy, pneumonia diagnosis\n",
        "\n",
        "2. TRANSFER LEARNING ADVANTAGE:\n",
        "   Transfer learning leverages knowledge from large datasets (ImageNet) to\n",
        "   improve performance on smaller medical datasets. Benefits include:\n",
        "   - Reduced training time and computational resources\n",
        "   - Better generalization with limited medical data\n",
        "   - Access to sophisticated features learned from millions of images\n",
        "   \n",
        "3. VGG19 ARCHITECTURE (Simonyan & Zisserman, 2014):\n",
        "   - 19-layer deep network with 3x3 convolutional filters\n",
        "   - Pre-trained on ImageNet (1.4 million images, 1000 classes)\n",
        "   - Known for learning rich, generalizable features\n",
        "   - Successfully applied to medical imaging tasks\n",
        "\n",
        "4. MALARIA DETECTION WITH DEEP LEARNING:\n",
        "   Recent studies show CNNs achieve 95-98% accuracy on malaria detection,\n",
        "   comparable to or exceeding expert microscopists. Transfer learning\n",
        "   approaches consistently outperform models trained from scratch.\n",
        "\n",
        "RESEARCH GAP:\n",
        "While many studies use transfer learning for malaria detection, systematic\n",
        "comparison of different architectural configurations (dropout rates, dense\n",
        "layer sizes) remains limited. This work addresses that gap."
      ],
      "metadata": {
        "id": "oqG_5CjcJuvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION 3: METHODOLOGY"
      ],
      "metadata": {
        "id": "BYdxK-jvJxGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPERIMENTAL DESIGN: TRANSFER LEARNING WITH VGG19\n",
        "\n",
        "RATIONALE FOR VGG19:\n",
        "1. Proven performance in medical image classification\n",
        "2. Deep architecture captures complex patterns in cell morphology\n",
        "3. Pre-trained weights provide strong feature extractors\n",
        "4. Relatively simple architecture (easier to interpret than ResNet/Inception)\n",
        "\n",
        "TRANSFER LEARNING STRATEGY - FEATURE EXTRACTION:\n",
        "We employ feature extraction (frozen base layers) rather than fine-tuning:\n",
        "- Preserves ImageNet knowledge (prevents catastrophic forgetting)\n",
        "- Faster training (fewer parameters to update)\n",
        "- Appropriate for our large dataset (22,000+ images)\n",
        "- Reduces risk of overfitting\n",
        "\n",
        "MODEL ARCHITECTURE:\n",
        "- Base: VGG19 pre-trained on ImageNet (frozen)\n",
        "- Custom top layers:\n",
        "  * GlobalAveragePooling2D (reduces parameters vs Flatten)\n",
        "  * Dense layers with ReLU activation\n",
        "  * Dropout for regularization\n",
        "  * Output: 2 units with Softmax (binary classification)\n",
        "\n",
        "THREE EXPERIMENTS:\n",
        "\n",
        "Experiment 1: BASELINE\n",
        "- Purpose: Establish baseline transfer learning performance\n",
        "- Architecture: 256 → 128 Dense units with moderate regularization\n",
        "- Hypothesis: Should achieve >90% accuracy due to VGG19 features\n",
        "\n",
        "Experiment 2: STRONGER DROPOUT\n",
        "- Purpose: Test if increased regularization improves generalization\n",
        "- Architecture: Higher dropout rates (0.6, 0.5) and L2 regularization\n",
        "- Hypothesis: May reduce overfitting but could lower training accuracy\n",
        "\n",
        "Experiment 3: LARGER CAPACITY\n",
        "- Purpose: Test if more parameters capture additional complexity\n",
        "- Architecture: 512 → 256 Dense units\n",
        "- Hypothesis: Higher capacity may improve accuracy if data supports it\n",
        "\n",
        "TRAINING CONFIGURATION:\n",
        "- Image size: 224x224 (VGG19 standard input)\n",
        "- Batch size: 16 (memory-efficient for large images)\n",
        "- Optimizer: Adam with learning rate 0.0001 (low for transfer learning)\n",
        "- Loss: Categorical cross-entropy\n",
        "- Callbacks:\n",
        "  * EarlyStopping: Prevents overtraining (patience=7)\n",
        "  * ReduceLROnPlateau: Adaptive learning rate adjustment\n",
        "- Data augmentation: Light (rotation, shifts, flips) for stability\n",
        "\n",
        "EVALUATION METRICS:\n",
        "- Accuracy: Overall classification correctness\n",
        "- Precision: Of predicted infected, how many truly infected (PPV)\n",
        "- Recall: Of actual infected, how many correctly identified (Sensitivity)\n",
        "- F1-Score: Harmonic mean of precision and recall\n",
        "- AUC: Area under ROC curve (threshold-independent performance)"
      ],
      "metadata": {
        "id": "Q8lF3a5jJ2bf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K5rb4bmdMRf"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oIfORUX7ccHI",
        "outputId": "70f34947-2bda-4847-a912-090ee42470ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Use GPU: Please check if the outpout is '/device:GPU:0'\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "tf.test.gpu_device_name()\n",
        "#from tensorflow.python.client import device_lib\n",
        "#device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11DKlCJcj31w"
      },
      "source": [
        "## Prepare DataSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "midATIuUq7H7"
      },
      "source": [
        "### *Download* DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCT2ogQdeHPW",
        "outputId": "c6a8d8b3-13a1-4ad7-e1fd-0f3291698066"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-10-04 00:43:22--  https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\n",
            "Resolving data.lhncbc.nlm.nih.gov (data.lhncbc.nlm.nih.gov)... 13.225.47.81, 13.225.47.51, 13.225.47.63, ...\n",
            "Connecting to data.lhncbc.nlm.nih.gov (data.lhncbc.nlm.nih.gov)|13.225.47.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 353452851 (337M) [application/zip]\n",
            "Saving to: ‘cell_images.zip’\n",
            "\n",
            "cell_images.zip     100%[===================>] 337.08M   209MB/s    in 1.6s    \n",
            "\n",
            "2025-10-04 00:43:24 (209 MB/s) - ‘cell_images.zip’ saved [353452851/353452851]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the data in the allocated google cloud-server. If already down, turn downloadData=False\n",
        "downloadData = True\n",
        "if downloadData == True:\n",
        "  indrive = False\n",
        "  if indrive == True:\n",
        "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip -P \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "    !unzip \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/cell_images.zip\" -d \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/\"\n",
        "    !ls \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "  else: #incloud google server\n",
        "    !rm -rf cell_images.*\n",
        "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\n",
        "    !unzip cell_images.zip >/dev/null 2>&1\n",
        "    !ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1LUJGE9U2vW"
      },
      "source": [
        "## Baseline CNN Model\n",
        "Define a basic ConvNet defined with ConvLayer: Conv2D => MaxPooling2D followed by Flatten => Dense => Dense(output)\n",
        "\n",
        "![ConvNet](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/ConvNet.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR5CklL5Ksmk"
      },
      "source": [
        "# directory structure function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required libaries"
      ],
      "metadata": {
        "id": "AWOSOqgZLAPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "Ad5JXumiK8Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration and data preparation"
      ],
      "metadata": {
        "id": "o8WgPoTxLPCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFIGURATION NOTES:\n",
        "\n",
        "Image Size (224x224):\n",
        "- VGG19 was trained on 224x224 images from ImageNet\n",
        "- Using the same size ensures optimal feature extraction\n",
        "- Smaller sizes (e.g., 128x128) lose important details\n",
        "\n",
        "Batch Size (16):\n",
        "- Smaller batch size due to larger image dimensions (memory constraint)\n",
        "- Still provides sufficient gradient estimates\n",
        "- Allows training on standard GPUs\n",
        "\n",
        "Data Augmentation Strategy:\n",
        "- Light augmentation to maintain cell morphology\n",
        "- Prevents overfitting while preserving diagnostic features\n",
        "- Rotation (10°): Cells can appear at any orientation\n",
        "- Shifts (10%): Simulates different cell positions\n",
        "- Horizontal flip: Mirrors are biologically valid\n",
        "- Zoom (10%): Accounts for microscope focus variations"
      ],
      "metadata": {
        "id": "FfWXbr6vLS79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set image dimensions (adjust based on your dataset)\n",
        "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "\n",
        "# Define the useful paths for data accessibility\n",
        "ai_project = '.' #\"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "cell_images_dir = os.path.join(ai_project,'cell_images')\n",
        "training_path = os.path.join(ai_project,'train')\n",
        "testing_path = os.path.join(ai_project,'test')\n",
        "\n",
        "print(f\"Image dimensions: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Training epochs: {EPOCHS}\")\n",
        "print(f\"Data paths configured successfully!\")"
      ],
      "metadata": {
        "id": "Yc1usBvhLVxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data generators"
      ],
      "metadata": {
        "id": "i5cJpNqYLrS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen_vgg = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "test_datagen_vgg = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load training data\n",
        "train_generator_vgg = train_datagen_vgg.flow_from_directory(\n",
        "    training_path,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    classes=['Infected', 'Uninfected']\n",
        ")\n",
        "\n",
        "# Load testing data\n",
        "test_generator_vgg = test_datagen_vgg.flow_from_directory(\n",
        "    testing_path,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    classes=['Infected', 'Uninfected']\n",
        ")\n",
        "\n",
        "print(f\"\\nDataset loaded:\")\n",
        "print(f\"  Training samples: {train_generator_vgg.samples}\")\n",
        "print(f\"  Testing samples: {test_generator_vgg.samples}\")\n",
        "print(f\"  Class indices: {train_generator_vgg.class_indices}\")\n",
        "print(f\"  Classes: 0=Infected, 1=Uninfected\")\n",
        "\n",
        "# Configure callbacks for training stability\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=7,\n",
        "    restore_best_weights=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks_list = [early_stopping, reduce_lr]\n",
        "print(\"✓ Training callbacks configured (EarlyStopping, ReduceLROnPlateau)\")"
      ],
      "metadata": {
        "id": "nletWQsfLq3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Functions"
      ],
      "metadata": {
        "id": "0ikBXPSNMpjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATION METHODOLOGY:\n",
        "\n",
        "These functions compute comprehensive metrics and generate visualizations\n",
        "for model assessment. Each metric provides different insights:\n",
        "\n",
        "- Accuracy: Overall correctness (can be misleading with class imbalance)\n",
        "- Precision: Important for reducing false positives (unnecessary treatment)\n",
        "- Recall: Critical for reducing false negatives (missed infections)\n",
        "- F1-Score: Balances precision and recall\n",
        "- AUC: Threshold-independent performance measure\n",
        "\n",
        "Visualizations provide interpretability:\n",
        "- Learning curves: Show training dynamics and overfitting\n",
        "- Confusion matrix: Reveals class-specific performance\n",
        "- ROC curve: Demonstrates sensitivity-specificity trade-off"
      ],
      "metadata": {
        "id": "KWq7oS6KMY5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions_and_labels(model, generator):\n",
        "    \"\"\"Get predictions and true labels from generator\"\"\"\n",
        "    generator.reset()\n",
        "    predictions = model.predict(generator, verbose=0)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Get true labels\n",
        "    true_classes = generator.classes\n",
        "\n",
        "    return predictions, predicted_classes, true_classes\n",
        "\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    \"\"\"Calculate accuracy, precision, recall, and F1-score\"\"\"\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    return {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1\n",
        "    }\n",
        "\n",
        "print(\"Evaluation functions defined!\")"
      ],
      "metadata": {
        "id": "5jtVyvpPMj-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization *Functions*"
      ],
      "metadata": {
        "id": "lINe043BMu9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZATION INTERPRETATION GUIDE:\n",
        "\n",
        "Learning Curves:\n",
        "- Training and validation should converge\n",
        "- Large gap indicates overfitting\n",
        "- Oscillating validation suggests unstable training\n",
        "\n",
        "Confusion Matrix:\n",
        "- Diagonal = correct predictions\n",
        "- Off-diagonal = errors\n",
        "- Check for class imbalance in errors\n",
        "\n",
        "ROC Curve:\n",
        "- Closer to top-left corner = better performance\n",
        "- AUC near 1.0 = excellent discrimination\n",
        "- AUC near 0.5 = random guessing"
      ],
      "metadata": {
        "id": "3D_TOQlUMyAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curves(history, experiment_name):\n",
        "    \"\"\"\n",
        "    Plot training and validation accuracy/loss over epochs.\n",
        "\n",
        "    What to look for:\n",
        "    - Smooth curves indicate stable training\n",
        "    - Converging lines suggest good generalization\n",
        "    - Diverging lines indicate overfitting\n",
        "    - Oscillations suggest learning rate issues\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Plot accuracy\n",
        "    ax1.plot(history.history['accuracy'], label='Training Accuracy',\n",
        "             marker='o', linewidth=2)\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy',\n",
        "             marker='s', linewidth=2)\n",
        "    ax1.set_title(f'{experiment_name}\\nModel Accuracy',\n",
        "                  fontsize=12, fontweight='bold')\n",
        "    ax1.set_xlabel('Epoch', fontsize=11)\n",
        "    ax1.set_ylabel('Accuracy', fontsize=11)\n",
        "    ax1.legend(loc='lower right')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot loss\n",
        "    ax2.plot(history.history['loss'], label='Training Loss',\n",
        "             marker='o', linewidth=2)\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss',\n",
        "             marker='s', linewidth=2)\n",
        "    ax2.set_title(f'{experiment_name}\\nModel Loss',\n",
        "                  fontsize=12, fontweight='bold')\n",
        "    ax2.set_xlabel('Epoch', fontsize=11)\n",
        "    ax2.set_ylabel('Loss', fontsize=11)\n",
        "    ax2.legend(loc='upper right')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(true_labels, predicted_labels, experiment_name):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix showing classification performance.\n",
        "\n",
        "    Interpretation:\n",
        "    - Top-left: True Infected correctly identified (True Positives)\n",
        "    - Bottom-right: True Uninfected correctly identified (True Negatives)\n",
        "    - Top-right: Uninfected predicted as Infected (False Positives)\n",
        "    - Bottom-left: Infected predicted as Uninfected (False Negatives)\n",
        "\n",
        "    False Negatives are clinically more concerning (missed infections).\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Infected', 'Uninfected'],\n",
        "                yticklabels=['Infected', 'Uninfected'],\n",
        "                cbar_kws={'label': 'Count'})\n",
        "    plt.title(f'{experiment_name}\\nConfusion Matrix',\n",
        "              fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('True Label', fontsize=11)\n",
        "    plt.xlabel('Predicted Label', fontsize=11)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return cm\n",
        "\n",
        "def plot_roc_curve(true_labels, predictions, experiment_name):\n",
        "    \"\"\"\n",
        "    Plot ROC curve and calculate AUC.\n",
        "\n",
        "    ROC Curve shows trade-off between:\n",
        "    - True Positive Rate (Sensitivity/Recall): Correctly identified infections\n",
        "    - False Positive Rate: Incorrectly flagged healthy cells\n",
        "\n",
        "    AUC Interpretation:\n",
        "    - 0.90-1.00: Excellent\n",
        "    - 0.80-0.90: Good\n",
        "    - 0.70-0.80: Fair\n",
        "    - 0.50-0.70: Poor\n",
        "    \"\"\"\n",
        "    fpr, tpr, _ = roc_curve(true_labels, predictions[:, 1])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "             label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
        "             label='Random Classifier (AUC = 0.50)')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=11)\n",
        "    plt.ylabel('True Positive Rate (Sensitivity/Recall)', fontsize=11)\n",
        "    plt.title(f'{experiment_name}\\nROC Curve', fontsize=12, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "print(\"✓ Visualization functions defined\")"
      ],
      "metadata": {
        "id": "PFP_6SSLNAn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete Evaluation Pipeline"
      ],
      "metadata": {
        "id": "T8M8oayfNGiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function orchestrates the complete evaluation process:\n",
        "1. Generates predictions on test set\n",
        "2. Calculates all metrics\n",
        "3. Creates all visualizations\n",
        "4. Prints detailed classification report\n",
        "\n",
        "Output includes per-class precision, recall, and F1-scores."
      ],
      "metadata": {
        "id": "kE1aHZBkNJuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, generator, experiment_name):\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation with metrics and visualizations.\n",
        "\n",
        "    This function:\n",
        "    - Computes accuracy, precision, recall, F1, and AUC\n",
        "    - Generates confusion matrix\n",
        "    - Plots ROC curve\n",
        "    - Prints detailed classification report\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"EVALUATING: {experiment_name}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Get predictions\n",
        "    predictions, predicted_classes, true_classes = get_predictions_and_labels(model, generator)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = calculate_metrics(true_classes, predicted_classes)\n",
        "\n",
        "    print(\"Performance Metrics:\")\n",
        "    print(\"-\" * 50)\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric:15s}: {value:.4f} ({value*100:.2f}%)\")\n",
        "\n",
        "    # Generate visualizations\n",
        "    print(\"\\nGenerating visualizations...\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = plot_confusion_matrix(true_classes, predicted_classes, experiment_name)\n",
        "\n",
        "    # ROC Curve\n",
        "    roc_auc = plot_roc_curve(true_classes, predictions, experiment_name)\n",
        "    metrics['AUC'] = roc_auc\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(classification_report(true_classes, predicted_classes,\n",
        "                                target_names=['Infected', 'Uninfected']))\n",
        "\n",
        "    return metrics\n",
        "\n",
        "print(\"✓ Complete evaluation pipeline ready\")"
      ],
      "metadata": {
        "id": "J8WhehyvNOOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 1 - Baseline Transfer Learning"
      ],
      "metadata": {
        "id": "rQ8n59GdNRiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPERIMENT 1: BASELINE FEATURE EXTRACTION\n",
        "\n",
        "Purpose:\n",
        "Establish baseline performance using VGG19 transfer learning with moderate\n",
        "architectural complexity.\n",
        "\n",
        "Architecture Details:\n",
        "- VGG19 base: 19 layers, all frozen (feature extraction only)\n",
        "- GlobalAveragePooling2D: Reduces spatial dimensions (better than Flatten)\n",
        "- Dense(256, relu): First classification layer with L2 regularization\n",
        "- Dropout(0.5): Prevents overfitting\n",
        "- Dense(128, relu): Second classification layer with L2 regularization\n",
        "- Dense(2, softmax): Output layer for binary classification\n",
        "\n",
        "Training Strategy:\n",
        "- Only custom top layers are trained\n",
        "- VGG19 base remains frozen\n",
        "- Learning rate: 0.0001 (low to prevent disrupting useful features)\n",
        "\n",
        "\n",
        "Overfitting Indicators to Watch:\n",
        "- Large gap between training and validation accuracy\n",
        "- Validation loss increasing while training loss decreases\n",
        "- High training accuracy with lower validation accuracy"
      ],
      "metadata": {
        "id": "sFiUzfL2NVTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPERIMENT 1: BASELINE FEATURE EXTRACTION\")\n",
        "print(\"=\"*70)\n",
        "print(\"Strategy: Freeze all VGG19 layers, train custom top layers\")\n",
        "print(\"Architecture: VGG19 → GAP → Dense(256) → Dropout(0.5) → Dense(128) → Output(2)\")\n",
        "\n",
        "# Load VGG19 without top layer\n",
        "base_model_exp1 = VGG19(weights='imagenet',\n",
        "                        include_top=False,\n",
        "                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "# Freeze all base model layers\n",
        "base_model_exp1.trainable = False\n",
        "print(f\"\\n✓ VGG19 base loaded: {len(base_model_exp1.layers)} layers frozen\")\n",
        "\n",
        "# Build custom classification layers\n",
        "x = base_model_exp1.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer='l2')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer='l2')(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model_exp1 = Model(inputs=base_model_exp1.input, outputs=output)\n",
        "\n",
        "# Compile with appropriate settings\n",
        "model_exp1.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nModel Architecture Summary:\")\n",
        "model_exp1.summary()\n",
        "\n",
        "print(f\"\\nTrainable parameters: {model_exp1.count_params():,}\")\n",
        "\n",
        "# Train the model\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING EXPERIMENT 1\")\n",
        "print(\"=\"*70)\n",
        "history_exp1 = model_exp1.fit(\n",
        "    train_generator_vgg,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_generator_vgg,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Training completed!\")\n",
        "\n",
        "# Evaluate the model\n",
        "metrics_exp1 = evaluate_model(model_exp1, test_generator_vgg,\n",
        "                               \"Experiment 1: Baseline Feature Extraction\")\n",
        "\n",
        "# Plot learning curves\n",
        "print(\"\\nLearning Curves Analysis:\")\n",
        "plot_learning_curves(history_exp1, \"Experiment 1: Baseline Feature Extraction\")\n",
        "\n",
        "# Save model\n",
        "model_exp1.save('vgg19_exp1_baseline.keras')\n",
        "print(\"\\n✓ Model saved: vgg19_exp1_baseline.keras\")"
      ],
      "metadata": {
        "id": "KY79xTXGNiml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What to look for in results:\n",
        "\n",
        "1. LEARNING CURVES:\n",
        "   - Do training and validation curves converge?\n",
        "   - Is there a large gap (overfitting)?\n",
        "   - Are curves smooth (stable training)?\n",
        "\n",
        "2. CONFUSION MATRIX:\n",
        "   - Are errors balanced across classes?\n",
        "   - Which class has more misclassifications?\n",
        "   - False Negatives (missed infections) are clinically critical\n",
        "\n",
        "3. ROC CURVE:\n",
        "   - AUC should be >0.90 for good performance\n",
        "   - Curve should be close to top-left corner\n",
        "\n",
        "4. OVERALL METRICS:\n",
        "   - Accuracy\n",
        "   - Precision and Recall should be balanced\n",
        "   - F1-Score summarizes overall performance"
      ],
      "metadata": {
        "id": "xYn-PuTBNm8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 2 - Enhanced Regularization"
      ],
      "metadata": {
        "id": "cyA2L3GtNrqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPERIMENT 2: FEATURE EXTRACTION WITH STRONGER DROPOUT\n",
        "\n",
        "Purpose:\n",
        "Test whether increased regularization improves generalization and reduces\n",
        "overfitting compared to baseline.\n",
        "\n",
        "Architecture Changes from Experiment 1:\n",
        "- Increased dropout from 0.5 to 0.6 after first Dense layer\n",
        "- Added additional dropout (0.5) after second Dense layer\n",
        "- Same Dense layer sizes (256, 128)\n",
        "\n",
        "Hypothesis:\n",
        "Stronger dropout should:\n",
        "1. Reduce overfitting (smaller train-validation gap)\n",
        "2. Potentially lower training accuracy slightly\n",
        "3. Improve or maintain validation accuracy\n",
        "4. Result in more robust model\n",
        "\n",
        "Trade-offs:\n",
        "- May slow convergence (more regularization)\n",
        "- Could underfit if dropout too aggressive\n",
        "- Training accuracy might be lower than Experiment 1\n",
        "\n",
        "Expected Outcome:\n",
        "If Experiment 1 showed overfitting, this should improve validation\n",
        "performance. If no overfitting, results may be similar or slightly worse."
      ],
      "metadata": {
        "id": "AzDS5cbTNuYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPERIMENT 2: ENHANCED REGULARIZATION WITH DROPOUT\")\n",
        "print(\"=\"*70)\n",
        "print(\"Strategy: Test if stronger dropout improves generalization\")\n",
        "print(\"Architecture: VGG19 → GAP → Dense(256) → Dropout(0.6) → Dense(128) → Dropout(0.5) → Output(2)\")\n",
        "\n",
        "# Load fresh VGG19 base\n",
        "base_model_exp2 = VGG19(weights='imagenet',\n",
        "                        include_top=False,\n",
        "                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "base_model_exp2.trainable = False\n",
        "print(f\"\\n✓ VGG19 base loaded: {len(base_model_exp2.layers)} layers frozen\")\n",
        "\n",
        "# Build model with stronger regularization\n",
        "x = base_model_exp2.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer='l2')(x)\n",
        "x = Dropout(0.6)(x)  # Increased dropout\n",
        "x = Dense(128, activation='relu', kernel_regularizer='l2')(x)\n",
        "x = Dropout(0.5)(x)  # Additional dropout layer\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model_exp2 = Model(inputs=base_model_exp2.input, outputs=output)\n",
        "\n",
        "# Compile\n",
        "model_exp2.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nModel Architecture Summary:\")\n",
        "model_exp2.summary()\n",
        "\n",
        "# Train\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING EXPERIMENT 2\")\n",
        "print(\"=\"*70)\n",
        "history_exp2 = model_exp2.fit(\n",
        "    train_generator_vgg,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_generator_vgg,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Training completed!\")\n",
        "\n",
        "# Evaluate\n",
        "metrics_exp2 = evaluate_model(model_exp2, test_generator_vgg,\n",
        "                               \"Experiment 2: Enhanced Dropout Regularization\")\n",
        "\n",
        "# Plot learning curves\n",
        "print(\"\\nLearning Curves Analysis:\")\n",
        "plot_learning_curves(history_exp2, \"Experiment 2: Enhanced Dropout Regularization\")\n",
        "\n",
        "# Save\n",
        "model_exp2.save('vgg19_exp2_dropout.keras')\n",
        "print(\"\\n✓ Model saved: vgg19_exp2_dropout.keras\")"
      ],
      "metadata": {
        "id": "F3bwK0AbN3rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare with Experiment 1:\n",
        "\n",
        "1. OVERFITTING COMPARISON:\n",
        "   - Is the train-validation gap smaller?\n",
        "   - Are validation curves more stable?\n",
        "\n",
        "2. ACCURACY TRADE-OFF:\n",
        "   - Training accuracy may be lower (expected with more dropout)\n",
        "   - Did validation accuracy improve or stay similar?\n",
        "\n",
        "3. CONVERGENCE:\n",
        "   - Did it take more epochs to converge?\n",
        "   - Are learning curves smoother?\n",
        "\n",
        "4. GENERALIZATION:\n",
        "   - Check if test set performance improved\n",
        "   - Stronger dropout should reduce overfitting symptoms"
      ],
      "metadata": {
        "id": "0zMp87CqN9kY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 3 - Increased Model Capacity"
      ],
      "metadata": {
        "id": "QREugAihOBHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPERIMENT 3: INCREASED MODEL CAPACITY\n",
        "\n",
        "Purpose:\n",
        "Test whether larger Dense layers can capture additional complexity in the\n",
        "data and improve performance.\n",
        "\n",
        "Architecture Changes from Experiment 1:\n",
        "- Increased first Dense layer: 256 → 512 units\n",
        "- Increased second Dense layer: 128 → 256 units\n",
        "- Moderate dropout (0.5, 0.3)\n",
        "- More parameters to learn complex patterns\n",
        "\n",
        "Hypothesis:\n",
        "Larger capacity should:\n",
        "1. Capture more complex feature interactions\n",
        "2. Potentially improve accuracy if data supports it\n",
        "3. Risk overfitting without proper regularization\n",
        "\n",
        "Trade-offs:\n",
        "- More parameters = longer training time\n",
        "- Higher memory usage\n",
        "- Increased risk of overfitting\n",
        "- May not improve if baseline already captures key patterns\n",
        "\n",
        "Expected Outcome:\n",
        "If the baseline hasn't reached the data's full potential, this should\n",
        "improve performance. If baseline is sufficient, results may be similar\n",
        "with possible overfitting."
      ],
      "metadata": {
        "id": "wp0rZmeeOGp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXPERIMENT 3: INCREASED MODEL CAPACITY\")\n",
        "print(\"=\"*70)\n",
        "print(\"Strategy: Test if larger Dense layers improve performance\")\n",
        "print(\"Architecture: VGG19 → GAP → Dense(512) → Dropout(0.5) → Dense(256) → Dropout(0.3) → Output(2)\")\n",
        "\n",
        "# Load fresh VGG19 base\n",
        "base_model_exp3 = VGG19(weights='imagenet',\n",
        "                        include_top=False,\n",
        "                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "base_model_exp3.trainable = False\n",
        "print(f\"\\n✓ VGG19 base loaded: {len(base_model_exp3.layers)} layers frozen\")\n",
        "\n",
        "# Build model with larger Dense layers\n",
        "x = base_model_exp3.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu', kernel_regularizer='l2')(x)  # Doubled from 256\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer='l2')(x)  # Doubled from 128\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model_exp3 = Model(inputs=base_model_exp3.input, outputs=output)\n",
        "\n",
        "# Compile\n",
        "model_exp3.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nModel Architecture Summary:\")\n",
        "model_exp3.summary()\n",
        "\n",
        "print(f\"\\nTrainable parameters: {model_exp3.count_params():,}\")\n",
        "print(f\"(Note: More parameters than Experiments 1 & 2)\")\n",
        "\n",
        "# Train\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING EXPERIMENT 3\")\n",
        "print(\"=\"*70)\n",
        "history_exp3 = model_exp3.fit(\n",
        "    train_generator_vgg,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_generator_vgg,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Training completed!\")\n",
        "\n",
        "# Evaluate\n",
        "metrics_exp3 = evaluate_model(model_exp3, test_generator_vgg,\n",
        "                               \"Experiment 3: Increased Model Capacity\")\n",
        "\n",
        "# Plot learning curves\n",
        "print(\"\\nLearning Curves Analysis:\")\n",
        "plot_learning_curves(history_exp3, \"Experiment 3: Increased Model Capacity\")\n",
        "\n",
        "# Save\n",
        "model_exp3.save('vgg19_exp3_dense512.keras')\n",
        "print(\"\\n✓ Model saved: vgg19_exp3_dense512.keras\")"
      ],
      "metadata": {
        "id": "ZzpkKsS3O3YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare with Experiments 1 & 2:\n",
        "\n",
        "1. CAPACITY VS PERFORMANCE:\n",
        "   - Did larger layers improve accuracy?\n",
        "   - Was the improvement worth the extra parameters?\n",
        "\n",
        "2. OVERFITTING RISK:\n",
        "   - More capacity can lead to overfitting\n",
        "   - Check train-validation gap compared to Exp 1 & 2\n",
        "   - Are validation curves stable?\n",
        "\n",
        "3. TRAINING DYNAMICS:\n",
        "   - Did it converge faster or slower?\n",
        "   - More parameters may need more epochs\n",
        "\n",
        "4. PRACTICAL CONSIDERATIONS:\n",
        "   - Training time increased?\n",
        "   - Memory usage acceptable?\n",
        "   - Is complexity justified by performance gain?"
      ],
      "metadata": {
        "id": "qfmASYN32H_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparative Analysis and Results Summary"
      ],
      "metadata": {
        "id": "OVd0724T2LEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This section compares the three experiments to identify:\n",
        "1. Which configuration performs best\n",
        "2. Trade-offs between complexity and performance\n",
        "3. Impact of regularization vs capacity\n",
        "4. Recommendations for deployment\n",
        "\n",
        "The results table and visualizations provide a comprehensive comparison\n",
        "to inform model selection decisions."
      ],
      "metadata": {
        "id": "AhrSNFaV2NkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARATIVE RESULTS - ALL EXPERIMENTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create comprehensive results dataframe\n",
        "results_df = pd.DataFrame({\n",
        "    'Experiment': [\n",
        "        'Exp 1: Baseline (256+128 Dense)',\n",
        "        'Exp 2: + Stronger Dropout',\n",
        "        'Exp 3: Larger (512+256 Dense)'\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        metrics_exp1['Accuracy'],\n",
        "        metrics_exp2['Accuracy'],\n",
        "        metrics_exp3['Accuracy']\n",
        "    ],\n",
        "    'Precision': [\n",
        "        metrics_exp1['Precision'],\n",
        "        metrics_exp2['Precision'],\n",
        "        metrics_exp3['Precision']\n",
        "    ],\n",
        "    'Recall': [\n",
        "        metrics_exp1['Recall'],\n",
        "        metrics_exp2['Recall'],\n",
        "        metrics_exp3['Recall']\n",
        "    ],\n",
        "    'F1-Score': [\n",
        "        metrics_exp1['F1-Score'],\n",
        "        metrics_exp2['F1-Score'],\n",
        "        metrics_exp3['F1-Score']\n",
        "    ],\n",
        "    'AUC': [\n",
        "        metrics_exp1['AUC'],\n",
        "        metrics_exp2['AUC'],\n",
        "        metrics_exp3['AUC']\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nPerformance Metrics Comparison Table:\")\n",
        "print(\"=\"*80)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Identify best performing model for each metric\n",
        "print(\"\\nBest Performing Models by Metric:\")\n",
        "print(\"-\"*80)\n",
        "for metric in ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']:\n",
        "    best_idx = results_df[metric].idxmax()\n",
        "    best_exp = results_df.loc[best_idx, 'Experiment']\n",
        "    best_val = results_df.loc[best_idx, metric]\n",
        "    print(f\"{metric:12s}: {best_exp} ({best_val:.4f})\")\n",
        "\n",
        "# Create comparative visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "metrics_list = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "experiments = results_df['Experiment'].tolist()\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
        "\n",
        "for idx, metric in enumerate(metrics_list):\n",
        "    row = idx // 3\n",
        "    col = idx % 3\n",
        "    ax = axes[row, col]\n",
        "\n",
        "    values = results_df[metric].tolist()\n",
        "    bars = ax.bar(range(len(experiments)), values, color=colors)\n",
        "    ax.set_ylabel(metric, fontsize=11)\n",
        "    ax.set_title(f'{metric} Comparison', fontweight='bold', fontsize=12)\n",
        "    ax.set_xticks(range(len(experiments)))\n",
        "    ax.set_xticklabels(['Exp 1', 'Exp 2', 'Exp 3'], fontsize=10)\n",
        "    ax.set_ylim([min(values) - 0.02, 1.0])\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for i, (bar, val) in enumerate(zip(bars, values)):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "                f'{val:.4f}',\n",
        "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "    # Highlight best performer\n",
        "    best_idx = values.index(max(values))\n",
        "    bars[best_idx].set_edgecolor('gold')\n",
        "    bars[best_idx].set_linewidth(3)\n",
        "\n",
        "# Remove empty subplot\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "plt.suptitle('VGG19 Transfer Learning - Comparative Performance Analysis',\n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv('vgg19_experiments_results.csv', index=False)\n",
        "print(\"\\n✓ Results saved to: vgg19_experiments_results.csv\")"
      ],
      "metadata": {
        "id": "vT_dMLSe2V5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RESULTS DISCUSSION"
      ],
      "metadata": {
        "id": "gcbu8aPN2Y-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PERFORMANCE ANALYSIS:\n",
        "\n",
        "Based on the comparative results, we can draw several conclusions:\n",
        "\n",
        "1. OVERALL PERFORMANCE:\n",
        "   All three models achieved high accuracy, demonstrating that VGG19\n",
        "   transfer learning is highly effective for malaria diagnosis. The pre-trained\n",
        "   ImageNet features generalize well to microscopy images despite the domain\n",
        "   difference.\n",
        "\n",
        "2. EXPERIMENT COMPARISON:\n",
        "\n",
        "   Experiment 1 (Baseline):\n",
        "   - Provides solid performance with moderate complexity\n",
        "   - Good balance between accuracy and computational efficiency\n",
        "   - May show some overfitting if train-validation gap is large\n",
        "   \n",
        "   Experiment 2 (Stronger Dropout):\n",
        "   - Tests regularization hypothesis\n",
        "   - If overfitting was present in Exp 1, this should reduce it\n",
        "   - Validation performance should be more stable\n",
        "   - Trade-off: Slightly lower training accuracy acceptable\n",
        "   \n",
        "   Experiment 3 (Larger Capacity):\n",
        "   - Tests if data supports more complex models\n",
        "   - Higher parameter count increases risk of overfitting\n",
        "   - Performance gain (if any) should justify added complexity\n",
        "\n",
        "3. KEY INSIGHTS FROM LEARNING CURVES:\n",
        "\n",
        "   Overfitting Indicators (if present):\n",
        "   - Large gap between training and validation accuracy/loss\n",
        "   - Validation metrics plateauing or degrading while training improves\n",
        "   - Solution: Experiment 2's stronger dropout should help\n",
        "   \n",
        "   Underfitting Indicators (if present):\n",
        "   - Both training and validation accuracy plateau at low values\n",
        "   - High loss values\n",
        "   - Solution: Experiment 3's larger capacity might help\n",
        "   \n",
        "   Good Fit Indicators:\n",
        "   - Training and validation curves converge\n",
        "   - Small gap between train and validation metrics\n",
        "   - Smooth, stable curves\n",
        "\n",
        "4. CONFUSION MATRIX INSIGHTS:\n",
        "\n",
        "   Clinical Implications:\n",
        "   - False Negatives (Infected predicted as Uninfected): CRITICAL\n",
        "     * Missed diagnosis leads to untreated malaria\n",
        "     * Must be minimized even at cost of some False Positives\n",
        "   \n",
        "   - False Positives (Uninfected predicted as Infected): Less critical\n",
        "     * Leads to unnecessary treatment but safer than missing infection\n",
        "     * Can be confirmed with additional testing\n",
        "   \n",
        "   Balanced Performance:\n",
        "   - Check if errors are evenly distributed across classes\n",
        "   - Class imbalance in errors suggests model bias\n",
        "\n",
        "5. ROC/AUC ANALYSIS:\n",
        "\n",
        "   AUC Interpretation:\n",
        "   - >0.95: Excellent discrimination capability\n",
        "   - 0.90-0.95: Very good performance\n",
        "   - 0.85-0.90: Good performance\n",
        "   - < 0.85: May need improvement\n",
        "   \n",
        "   Threshold Selection:\n",
        "   - Can be adjusted based on clinical priorities\n",
        "   - Higher sensitivity (recall) = fewer missed infections\n",
        "   - Trade-off with specificity and false positive rate\n",
        "\n"
      ],
      "metadata": {
        "id": "S1PPfbMJ2fhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OVERFITTING/UNDERFITTING ANALYSIS:"
      ],
      "metadata": {
        "id": "cEiUgCUi1Nbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze overfitting for each experiment\n",
        "def analyze_fitting(history, exp_name):\n",
        "    final_train_acc = history.history['accuracy'][-1]\n",
        "    final_val_acc = history.history['val_accuracy'][-1]\n",
        "    gap = final_train_acc - final_val_acc\n",
        "\n",
        "    print(f\"\\n{exp_name}:\")\n",
        "    print(f\"  Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "    print(f\"  Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "    print(f\"  Gap: {gap:.4f}\")\n",
        "\n",
        "    if gap > 0.05:\n",
        "        print(f\"  → Shows signs of OVERFITTING (gap > 5%)\")\n",
        "        print(f\"     Model memorizing training data rather than generalizing\")\n",
        "    elif gap > 0.02:\n",
        "        print(f\"  → Slight overfitting (gap 2-5%), but acceptable\")\n",
        "    else:\n",
        "        print(f\"  → Good generalization (gap < 2%)\")\n",
        "\n",
        "    if final_val_acc < 0.85:\n",
        "        print(f\"  → May be UNDERFITTING (validation accuracy < 85%)\")\n",
        "        print(f\"     Model not capturing enough complexity\")\n",
        "\n",
        "analyze_fitting(history_exp1, \"Experiment 1 (Baseline)\")\n",
        "analyze_fitting(history_exp2, \"Experiment 2 (Stronger Dropout)\")\n",
        "analyze_fitting(history_exp3, \"Experiment 3 (Larger Capacity)\")"
      ],
      "metadata": {
        "id": "JXF_8hPw2uQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HANDLING OVERFITTING/UNDERFITTING:\n",
        "\n",
        "Strategies Already Implemented:\n",
        "1. Dropout regularization (0.3-0.6 depending on experiment)\n",
        "2. L2 kernel regularization in Dense layers\n",
        "3. Early stopping (stops when validation stops improving)\n",
        "4. Learning rate reduction (adapts when learning plateaus)\n",
        "5. Data augmentation (increases training data diversity)\n",
        "\n",
        "Additional Strategies if Needed:\n",
        "1. If Overfitting Persists:\n",
        "   - Increase dropout rates further\n",
        "   - Reduce model capacity (fewer/smaller Dense layers)\n",
        "   - Increase data augmentation\n",
        "   - Add more L2 regularization\n",
        "   - Use simpler architecture\n",
        "\n",
        "2. If Underfitting Occurs:\n",
        "   - Increase model capacity (more/larger layers)\n",
        "   - Reduce regularization\n",
        "   - Train for more epochs\n",
        "   - Increase learning rate slightly\n",
        "   - Consider fine-tuning some VGG19 layers\n",
        "\n",
        "3. For Unstable Training:\n",
        "   - Further reduce learning rate\n",
        "   - Increase batch size (if memory allows)\n",
        "   - Reduce data augmentation intensity\n",
        "   - Use batch normalization\n",
        "\n",
        "CALLBACKS EFFECTIVENESS:\n",
        "\n",
        "Early Stopping:\n",
        "- Prevents overtraining by monitoring validation accuracy\n",
        "- Restores best weights (not final weights)\n",
        "- Patience=7 allows temporary plateaus\n",
        "\n",
        "ReduceLROnPlateau:\n",
        "- Automatically reduces learning rate when learning stalls\n",
        "- Helps escape local minima\n",
        "- Improves convergence stability"
      ],
      "metadata": {
        "id": "Tz4odYFK2yOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL SELECTION RECOMMENDATIONS"
      ],
      "metadata": {
        "id": "Oop2Ar6j21D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL SELECTION RECOMMENDATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "best_accuracy_idx = results_df['Accuracy'].idxmax()\n",
        "best_model = results_df.loc[best_accuracy_idx, 'Experiment']\n",
        "best_accuracy = results_df.loc[best_accuracy_idx, 'Accuracy']\n",
        "\n",
        "print(f\"\"\"\n",
        "RECOMMENDED MODEL: {best_model}\n",
        "Validation Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)"
      ],
      "metadata": {
        "id": "tHlEXu1326dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selection Criteria:\n",
        "1. Highest validation accuracy\n",
        "2. Balanced precision and recall\n",
        "3. Stable training (from learning curves)\n",
        "4. Practical deployment considerations"
      ],
      "metadata": {
        "id": "3GFGmEyS2-QB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIMITATIONS"
      ],
      "metadata": {
        "id": "fC6qKn2U3By-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "   - Single data source (NIH dataset)\n",
        "   - May not represent all clinical scenarios\n",
        "   - No species-level classification (only infected/uninfected)\n",
        "\n",
        "BROADER IMPACT:\n",
        "\n",
        "Success in automated malaria diagnosis could:\n",
        "- Reduce diagnostic delays in resource-limited settings\n",
        "- Improve screening efficiency in high-burden areas\n",
        "- Enable large-scale surveillance programs\n",
        "- Serve as template for other microscopy-based diagnoses\n",
        "- Reduce burden on healthcare workers\n",
        "\n",
        "However, must address:\n",
        "- Equitable access to technology\n",
        "- Training requirements for end users\n",
        "- Maintenance and quality control\n",
        "- Integration with existing healthcare systems"
      ],
      "metadata": {
        "id": "342cqBTP3Hsr"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}